{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "restricted_negative_reward_4x4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JV59E-Xtzc6C"
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ra0EQ9tizpV4"
      },
      "source": [
        "map = ['SFFF',\n",
        "          'FHFH',\n",
        "          'HFFH',\n",
        "          'HFFG']\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dO5TnTwPzs70",
        "outputId": "5e847207-af66-485c-efa2-4d9b2ffc789d"
      },
      "source": [
        "env = gym.make('FrozenLake-v0', is_slippery=False, desc = map)\n",
        "\n",
        "\n",
        "# visualize 4x4 frozen lake\n",
        "env.render()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "HFFH\n",
            "HFFG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBFCpO8OzvNr",
        "outputId": "54063993-3402-450a-b774-749128385ca7"
      },
      "source": [
        "# Total number of States and Actions\n",
        "n_states = env.observation_space.n\n",
        "n_actions = env.action_space.n\n",
        "n_rows = 4\n",
        "n_cols = 4\n",
        "print( \"States = \", n_states)\n",
        "print( \"Actions = \", n_actions)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "States =  16\n",
            "Actions =  4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYm5nuVA6Sd0"
      },
      "source": [
        "def restrict_actions(Q, n_states, n_rows):\n",
        "\n",
        "  Q.at[n_states -1, :] = np.zeros(n_actions,)\n",
        "  for i in range( 0, n_states, n_rows): \n",
        "    Q.at[i,0] = np.NaN\n",
        "  for i in range( n_rows -1 , n_states, n_rows): \n",
        "    Q.at[i,2] = np.NaN\n",
        "  for i in range(0, n_rows):\n",
        "    Q.at[i,3] = np.NaN\n",
        "  for i in range(n_states - n_rows , n_states):\n",
        "    Q.at[i,1 ]= np.NaN\n",
        "  \n",
        "  return Q\n",
        "  "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZBSdQuX6USH"
      },
      "source": [
        "def choose_action(Q, state, epsilon):\n",
        "  random_for_epsilon = np.random.rand()\n",
        "  if random_for_epsilon <= epsilon:\n",
        "    s = Q.loc[state].notna()\n",
        "    vals = s[s].index.values\n",
        "    action = random.choice(vals)\n",
        "  else: \n",
        "    Q.loc[state] += np.random.rand(n_actions,)/100\n",
        "    action = np.argmax(Q.loc[state])\n",
        "  return action"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukabhEO16spn"
      },
      "source": [
        "def rewarder(new_state, reward):\n",
        "  if map[rowsandcols(new_state)[0]][rowsandcols(new_state)[1]]== 'H':\n",
        "    reward -= 20\n",
        "  elif map[rowsandcols(new_state)[0]][rowsandcols(new_state)[1]]== 'F':\n",
        "    reward -= 1 \n",
        "  elif map[rowsandcols(new_state)[0]][rowsandcols(new_state)[1]]== 'S':\n",
        "    reward -= 1\n",
        "  else: #goal\n",
        "    reward += 100\n",
        "\n",
        "  return reward"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zaFrxWw6Wfc"
      },
      "source": [
        "##assign index to each state using state-matrix\n",
        "\n",
        "state_matrix = np.arange(0,n_states).reshape(n_rows,n_cols)\n",
        "state_matrix\n",
        "\n",
        "def rowsandcols(state):\n",
        "  ''' input: state returned by env\n",
        "      output: location of state as (row,col) tuple'''\n",
        "  return int(np.where(state_matrix ==state)[0]), int(np.where(state_matrix ==state)[1])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L52ggN096YRQ"
      },
      "source": [
        "reps = 100\n",
        "num_episodes = 1000"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEh2N-Rg6Z6C"
      },
      "source": [
        "n_successes = []\n",
        "\n",
        "for i_rep in range(reps):\n",
        "  \n",
        "  steps_total = [] # store number of steps taken in each episode\n",
        "  rewards_total = [] #store reward obtained for each episode\n",
        "  epsilon_total = [] #store epsilon obtained at the end of each episode\n",
        "  terminal_state = [] \n",
        "\n",
        "  epsilon = 0.8\n",
        "  epsilon_final = 0.1\n",
        "  epsilon_decay = 0.999\n",
        "  gamma = 0.90 # discount factor\n",
        "  learning_rate = 0.9 #how important is the difference between q-val from q-table and what's observed\n",
        "\n",
        "  Q = pd.DataFrame(np.random.rand(n_states,n_actions)/1000)\n",
        "  Q.loc[15] = np.zeros(n_actions,)\n",
        "  Q = restrict_actions(Q, n_states, n_rows)\n",
        "\n",
        "  for i_episode in range(num_episodes):\n",
        "    \n",
        "    # resets the environment\n",
        "    state = env.reset()\n",
        "    step = 0\n",
        "    reward = 0\n",
        "\n",
        "  ## as epsilon decays with more timesteps, the prob. of selecting a random val < e decays --> more likely to exploit. \n",
        "    if epsilon > epsilon_final:\n",
        "            epsilon *= epsilon_decay\n",
        "\n",
        "    while True:\n",
        "        \n",
        "        step += 1\n",
        "        \n",
        "        action = choose_action(Q, state, epsilon)\n",
        "  \n",
        "         \n",
        "        ## env gives reward and next state and whether we've reached terminal state upon taking action at current state.. \n",
        "        new_state, _ , done, info = env.step(action)\n",
        "\n",
        "        ##if you want reward penalized at for each timestep\n",
        "        reward = rewarder(new_state, reward)\n",
        "\n",
        "        # filling the Q Table - \n",
        "        \n",
        "        Q.loc[state, action] = (1- learning_rate)*Q.at[state, action] + learning_rate*(reward + gamma * np.max(Q.loc[new_state]))\n",
        "        \n",
        "        # Setting new state for next action\n",
        "        state = new_state\n",
        "        tile = map[rowsandcols(state)[0]][rowsandcols(state)[1]]\n",
        "        #env.render()\n",
        "        \n",
        "        if done:\n",
        "          #print(Q)\n",
        "          \n",
        "          terminal_state.append(tile)\n",
        "          #steps_total.append(step)\n",
        "          #rewards_total.append(reward)\n",
        "          #epsilon_total.append(epsilon)\n",
        "          #if i_episode % 10 == 0:\n",
        "            #print('Episode: {} Reward: {} Steps Taken: {} Terminal State: {}, Epsilon: {}'.format(i_episode,reward, step, tile, epsilon))\n",
        "          break\n",
        "  n_successes.append(terminal_state.count('G'))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hJp--Wo63u3",
        "outputId": "c2b5b33d-91f2-4efc-c898-c9d5443a8caf"
      },
      "source": [
        "np.mean(n_successes)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "315.28"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGKnDNpa9WjL",
        "outputId": "3e830174-541e-43d5-f8d5-5b2260dd8d8b"
      },
      "source": [
        "np.std(n_successes)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15.988170627060493"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLP1GYuw9jaq"
      },
      "source": [
        "import plotly.express as px"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "6_qCZ3pJ9Z3e",
        "outputId": "bf3340a5-b24a-497f-d71a-fbfa1b0611b5"
      },
      "source": [
        "\n",
        "fig = px.bar( x= np.arange(1,101), y= n_successes)\n",
        "fig.update_layout(\n",
        "    title=\"N_success 4x4 with negative reward structure and restricted actions\",\n",
        "    xaxis=dict(\n",
        "        title='rep',\n",
        "        tickmode='linear'),\n",
        "    yaxis_title=\"n_successes per 1000 episodes\",\n",
        "    font=dict(\n",
        "        family=\"Courier New, monospace\",\n",
        "        size=18))\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"7e1bfbdb-d7b7-4f98-b732-b66a6f43cf1a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"7e1bfbdb-d7b7-4f98-b732-b66a6f43cf1a\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '7e1bfbdb-d7b7-4f98-b732-b66a6f43cf1a',\n",
              "                        [{\"alignmentgroup\": \"True\", \"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"x=%{x}<br>y=%{y}\", \"legendgroup\": \"\", \"marker\": {\"color\": \"#636efa\"}, \"name\": \"\", \"offsetgroup\": \"\", \"orientation\": \"v\", \"showlegend\": false, \"textposition\": \"auto\", \"type\": \"bar\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100], \"xaxis\": \"x\", \"y\": [314, 320, 330, 306, 314, 319, 304, 310, 322, 323, 290, 298, 315, 323, 325, 321, 318, 317, 327, 295, 313, 318, 342, 321, 314, 304, 325, 304, 311, 330, 312, 297, 327, 336, 309, 334, 298, 329, 330, 311, 322, 318, 292, 329, 329, 318, 329, 342, 315, 327, 326, 317, 279, 299, 341, 324, 334, 326, 237, 328, 293, 333, 322, 305, 324, 291, 313, 331, 336, 303, 324, 295, 304, 312, 346, 306, 321, 318, 303, 279, 334, 313, 325, 326, 302, 330, 314, 306, 330, 303, 304, 313, 316, 295, 296, 307, 312, 338, 303, 314], \"yaxis\": \"y\"}],\n",
              "                        {\"barmode\": \"relative\", \"font\": {\"family\": \"Courier New, monospace\", \"size\": 18}, \"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"N_success 4x4 with negative reward structure and restricted actions\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"tickmode\": \"linear\", \"title\": {\"text\": \"rep\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"n_successes per 1000 episodes\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('7e1bfbdb-d7b7-4f98-b732-b66a6f43cf1a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rw5lb5pY9ryT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}