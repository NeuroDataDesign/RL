{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DMST_V2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kw9VGZ_tKKb2"
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJi6LUvDKNov"
      },
      "source": [
        "map1 = ['GASBG']\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egYCm62xKPMX"
      },
      "source": [
        "map2 = ['GBSAG']\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZWHNfWOKQWT",
        "outputId": "48b2a86a-b267-470d-8ed7-97fc715057a2"
      },
      "source": [
        "\n",
        "env1 = gym.make('FrozenLake-v0', is_slippery=False, desc = map1)\n",
        "\n",
        "env1.render()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "GA\u001b[41mS\u001b[0mBG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJSzwSRvK3UC",
        "outputId": "0ee0c618-e832-4ddb-d4a8-e0fad65494d3"
      },
      "source": [
        "\n",
        "env2 = gym.make('FrozenLake-v0', is_slippery=False, desc = map2)\n",
        "\n",
        "env2.render()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "GB\u001b[41mS\u001b[0mAG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBi8j_MoK4vR",
        "outputId": "fb720aa1-5458-41b7-c63f-6f915057fd1b"
      },
      "source": [
        "# Total number of States and Actions\n",
        "n_states = env1.observation_space.n\n",
        "n_actions = 4\n",
        "n_rows = 1\n",
        "n_cols = 5\n",
        "print( \"States = \", n_states)\n",
        "print( \"Actions = \", n_actions)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "States =  5\n",
            "Actions =  4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WL8bIjwxK6Pb",
        "outputId": "8cc05d9f-0c7a-4204-e71a-887d4664cedd"
      },
      "source": [
        "# Total number of States and Actions\n",
        "n_states = env2.observation_space.n\n",
        "n_actions = 4\n",
        "n_rows = 1\n",
        "n_cols = 5\n",
        "print( \"States = \", n_states)\n",
        "print( \"Actions = \", n_actions)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "States =  5\n",
            "Actions =  4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOlQ7Gb-K71s"
      },
      "source": [
        "def restrict_actions(Q, n_states, n_rows):\n",
        "\n",
        "  Q.at[n_states -1, :] = np.zeros(n_actions,)\n",
        "  Q.at[0, :] = np.zeros(n_actions,)\n",
        "  for i in range( 0, n_states, n_rows): \n",
        "    Q.at[i,0] = np.NaN\n",
        "  for i in range( n_rows -1 , n_states, n_rows): \n",
        "    Q.at[i,2] = np.NaN\n",
        "  for i in range(0, n_rows):\n",
        "    Q.at[i,3] = np.NaN\n",
        "  for i in range(n_states - n_rows , n_states):\n",
        "    Q.at[i,1 ]= np.NaN\n",
        "  \n",
        "  return Q\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASW4V7zOK-kw"
      },
      "source": [
        "def choose_action(Q, state, epsilon):\n",
        "  random_for_epsilon = np.random.rand()\n",
        "  if random_for_epsilon <= epsilon:\n",
        "    action = random.choice((0,2))\n",
        "  elif Q.loc[state,2] > Q.loc[state,0]: \n",
        "   action = 2\n",
        "  elif Q.loc[state,0] > Q.loc[state,2]: \n",
        "    action = 0\n",
        "  elif Q.loc[state,0] == Q.loc[state,2]: \n",
        "    action = random.choice((0,2))\n",
        "  return action"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFmRBj83LAIY"
      },
      "source": [
        "##assign index to each state using state-matrix\n",
        "\n",
        "state_matrix = np.arange(0,n_states).reshape(n_rows,n_cols)\n",
        "state_matrix\n",
        "\n",
        "def rowsandcols(state):\n",
        "  ''' input: state returned by env\n",
        "      output: location of state as (row,col) tuple'''\n",
        "  return int(np.where(state_matrix ==state)[0]), int(np.where(state_matrix ==state)[1])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwBCQnh7LB6s"
      },
      "source": [
        "def rewarder1(new_state, reward, entrance_stimulus):  #ENV1\n",
        "\n",
        "  if entrance_stimulus == 'A':\n",
        "    if new_state == 0: \n",
        "      reward += 100\n",
        "    else:\n",
        "      reward -= 10\n",
        "\n",
        "  if entrance_stimulus == 'B':\n",
        "    if new_state == 4:\n",
        "      reward += 100\n",
        "    else:\n",
        "      reward -= 10\n",
        "\n",
        "  return reward"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-qgJwv0LECI"
      },
      "source": [
        "def rewarder2(new_state, reward, entrance_stimulus): #ENV2\n",
        "\n",
        "  if entrance_stimulus == 'A':\n",
        "    if new_state == 4:\n",
        "      reward += 100\n",
        "    else:\n",
        "      reward -= 10\n",
        "\n",
        "  if entrance_stimulus == 'B':\n",
        "    if new_state == 0:\n",
        "      reward += 100\n",
        "    else:\n",
        "      reward -= 10\n",
        "\n",
        "  return reward"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UB0wFQUcLGGN"
      },
      "source": [
        "reps = 1\n",
        "num_episodes = 1500\n",
        "steps_total = [] # store number of steps taken in each episode\n",
        "rewards_total = [] #store reward obtained for each episode\n",
        "epsilon_total = [] #store epsilon obtained at the end of each episode\n",
        "terminal_state = []"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJvg5QhuLKBT",
        "outputId": "0dc134eb-00d5-4fcc-b441-85e4e226a5f1"
      },
      "source": [
        "for i in range(reps):\n",
        "  \n",
        "  epsilon = 0.8\n",
        "  epsilon_final = 0.1\n",
        "  epsilon_decay = 0.99\n",
        "\n",
        "  gamma = 0.90 # discount factor\n",
        "  learning_rate = 0.9 #how important is the difference between q-val from q-table and what's observed\n",
        "\n",
        "  Q1 = pd.DataFrame(np.random.rand(n_states,n_actions)/1000)\n",
        "  Q2 = pd.DataFrame(np.random.rand(n_states,n_actions)/1000)\n",
        "  Q3 = pd.DataFrame(np.random.rand(n_states,n_actions)/1000)\n",
        "  Q4 = pd.DataFrame(np.random.rand(n_states,n_actions)/1000)\n",
        "  #Q .loc[n_states-1] = np.zeros(n_actions,)\n",
        "  #Q.loc[n_cols-1] = np.zeros(n_actions,) \n",
        "  #Q = restrict_actions(Q, 5, 1)\n",
        "\n",
        "  for i_episode in range(num_episodes):\n",
        "\n",
        "    if np.random.randn() > 0.5: \n",
        "      entrance_stimulus = 'A'\n",
        "    else: \n",
        "      entrance_stimulus = 'B'\n",
        "\n",
        "    if epsilon > epsilon_final and i_episode%2!=0:\n",
        "            epsilon *= epsilon_decay\n",
        "\n",
        "\n",
        "    \n",
        "    # env1 and entrance stimulus = 'A', Q1\n",
        "\n",
        "\n",
        "    if i_episode%2==0 and entrance_stimulus == 'A' :\n",
        "      state = env1.reset()\n",
        "      step = 0\n",
        "      reward = 0\n",
        "\n",
        "      while True:\n",
        "        step += 1\n",
        "\n",
        "        random_for_epsilon = np.random.randn()\n",
        "\n",
        "        action = choose_action(Q1, state, epsilon)\n",
        "        \n",
        "\n",
        "         \n",
        "        ## env gives reward and next state and whether we've reached terminal state upon taking action at current state.. \n",
        "        new_state, _ , done, info = env1.step(action)\n",
        "\n",
        "        ##if you want reward penalized at for each timestep\n",
        "        reward = rewarder1(new_state, reward, entrance_stimulus)\n",
        "\n",
        "        \n",
        "        # filling the Q Table - \n",
        "        \n",
        "        Q1.loc[state, action] = (1- learning_rate)*(Q1.at[state, action]) + (learning_rate)*(reward+ gamma*(np.max(Q1.loc[new_state, [0,2]])))\n",
        "        \n",
        "        # Setting new state for next action\n",
        "        state = new_state\n",
        "        env1.render()\n",
        "\n",
        "        if done:\n",
        "          print('Episode: {} Reward: {} Steps Taken: {} , Epsilon: {}, Entrance_Stimulus: {}, Environment: {}'.format(i_episode,reward, step,  epsilon, entrance_stimulus, map1  ))\n",
        "          steps_total.append(step)\n",
        "          break\n",
        "\n",
        "\n",
        "      # env1 and entrance stimulus = 'B' , Q2\n",
        "\n",
        "\n",
        "    elif i_episode%2==0 and entrance_stimulus == 'B':\n",
        "      state = env1.reset()\n",
        "      step = 0\n",
        "      reward = 0\n",
        "\n",
        "      while True:\n",
        "        step += 1\n",
        "\n",
        "        random_for_epsilon = np.random.randn()\n",
        "\n",
        "        action = choose_action(Q2, state, epsilon)\n",
        "        \n",
        "\n",
        "         \n",
        "        ## env gives reward and next state and whether we've reached terminal state upon taking action at current state.. \n",
        "        new_state, _ , done, info = env1.step(action)\n",
        "\n",
        "        ##if you want reward penalized at for each timestep\n",
        "        reward = rewarder1(new_state, reward, entrance_stimulus)\n",
        "\n",
        "        \n",
        "        # filling the Q Table - \n",
        "        \n",
        "        Q2.loc[state, action] = (1- learning_rate)*(Q2.at[state, action]) + (learning_rate)*(reward+ gamma*(np.max(Q2.loc[new_state, [0,2]])))\n",
        "        \n",
        "        # Setting new state for next action\n",
        "        state = new_state\n",
        "        env2.render()\n",
        "\n",
        "\n",
        "        if done:\n",
        "          print('Episode: {} Reward: {} Steps Taken: {} , Epsilon: {}, Entrance_Stimulus: {}, Environment:{} '.format(i_episode,reward, step,  epsilon, entrance_stimulus, map2 ))\n",
        "          steps_total.append(step)\n",
        "          break\n",
        "    \n",
        "\n",
        "    # env2 and entrance stimulus = 'A' , Q3\n",
        "\n",
        "    elif i_episode%2!=0 and entrance_stimulus == 'A':\n",
        "      state = env2.reset()\n",
        "      step = 0\n",
        "      reward = 0\n",
        "\n",
        "      while True:\n",
        "        step += 1\n",
        "\n",
        "        random_for_epsilon = np.random.randn()\n",
        "\n",
        "        action = choose_action(Q3, state, epsilon)\n",
        "        \n",
        "\n",
        "         \n",
        "        ## env gives reward and next state and whether we've reached terminal state upon taking action at current state.. \n",
        "        new_state, _ , done, info = env2.step(action)\n",
        "\n",
        "        ##if you want reward penalized at for each timestep\n",
        "        reward = rewarder2(new_state, reward, entrance_stimulus)\n",
        "\n",
        "        \n",
        "        # filling the Q Table - \n",
        "        \n",
        "        Q3.loc[state, action] = (1- learning_rate)*(Q3.at[state, action]) + (learning_rate)*(reward+ gamma*(np.max(Q3.loc[new_state, [0,2]])))\n",
        "        \n",
        "        # Setting new state for next action\n",
        "        state = new_state\n",
        "        env2.render()\n",
        "\n",
        "\n",
        "        if done:\n",
        "          print('Episode: {} Reward: {} Steps Taken: {} , Epsilon: {}, Entrance_Stimulus: {}, Environment:{} '.format(i_episode,reward, step,  epsilon, entrance_stimulus, map2 ))\n",
        "          steps_total.append(step)\n",
        "          break\n",
        "    \n",
        "\n",
        "    #  env2 and entrance stimulus = 'B', Q4\n",
        "    elif i_episode%2!=0 and entrance_stimulus == 'B':\n",
        "      state = env2.reset()\n",
        "      step = 0\n",
        "      reward = 0\n",
        "\n",
        "      while True:\n",
        "        step += 1\n",
        "\n",
        "        random_for_epsilon = np.random.randn()\n",
        "\n",
        "        action = choose_action(Q4, state, epsilon)\n",
        "        \n",
        "\n",
        "         \n",
        "        ## env gives reward and next state and whether we've reached terminal state upon taking action at current state.. \n",
        "        new_state, _ , done, info = env2.step(action)\n",
        "\n",
        "        ##if you want reward penalized at for each timestep\n",
        "        reward = rewarder2(new_state, reward, entrance_stimulus)\n",
        "\n",
        "        \n",
        "        # filling the Q Table - \n",
        "        \n",
        "        Q4.loc[state, action] = (1- learning_rate)*(Q4.at[state, action]) + (learning_rate)*(reward+ gamma*(np.max(Q4.loc[new_state, [0,2]])))\n",
        "        \n",
        "        # Setting new state for next action\n",
        "        state = new_state\n",
        "        env2.render()\n",
        "\n",
        "\n",
        "        if done:\n",
        "          print('Episode: {} Reward: {} Steps Taken: {} , Epsilon: {}, Entrance_Stimulus: {}, Environment:{} '.format(i_episode,reward, step,  epsilon, entrance_stimulus, map2 ))\n",
        "          steps_total.append(step)\n",
        "          break\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 573 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 574 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 575 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 576 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 577 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 578 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 579 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 580 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 581 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 582 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 583 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 584 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 585 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 586 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 587 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 588 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 589 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 590 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 591 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 592 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 593 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 594 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 595 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 596 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 597 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 598 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 599 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 600 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 601 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 602 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Right)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 603 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 604 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 605 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 606 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 607 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 608 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 609 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GAS\u001b[41mB\u001b[0mG\n",
            "  (Right)\n",
            "GASB\u001b[41mG\u001b[0m\n",
            "Episode: 610 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 611 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 612 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Left)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 613 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 614 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 615 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 616 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 617 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 618 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 619 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 620 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Right)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 621 Reward: -40 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 622 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 623 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 624 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 625 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 626 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 627 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 628 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Left)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 629 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 630 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 631 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 632 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 633 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 634 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 635 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 636 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 637 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 638 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 639 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 640 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 641 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 642 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 643 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 644 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 645 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GAS\u001b[41mB\u001b[0mG\n",
            "  (Right)\n",
            "GASB\u001b[41mG\u001b[0m\n",
            "Episode: 646 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Right)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 647 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 648 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Left)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 649 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 650 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 651 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 652 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 653 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 654 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 655 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 656 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 657 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Right)\n",
            "GA\u001b[41mS\u001b[0mBG\n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 658 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 659 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 660 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 661 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 662 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 663 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 664 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 665 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 666 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 667 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 668 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 669 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 670 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 671 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 672 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 673 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 674 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 675 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 676 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Right)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 677 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 678 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 679 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 680 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 681 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 682 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 683 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 684 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 685 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 686 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 687 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 688 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 689 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 690 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 691 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 692 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 693 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 694 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 695 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 696 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 697 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 698 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 699 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 700 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 701 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 702 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Left)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 703 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 704 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 705 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 706 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 707 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 708 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 709 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 710 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 711 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 712 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 713 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 714 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 715 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 716 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Left)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 717 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 718 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 719 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 720 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 721 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 722 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 723 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 724 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Left)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 725 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 726 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 727 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 728 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 729 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 730 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 731 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 732 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Left)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 733 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 734 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 735 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 736 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 737 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 738 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 739 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 740 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 741 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 742 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 743 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 744 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 745 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 746 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 747 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 748 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 749 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 750 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 751 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GAS\u001b[41mB\u001b[0mG\n",
            "  (Right)\n",
            "GASB\u001b[41mG\u001b[0m\n",
            "Episode: 752 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 753 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 754 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 755 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 756 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 757 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 758 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 759 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 760 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 761 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 762 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 763 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 764 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 765 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 766 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 767 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 768 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 769 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 770 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 771 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 772 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 773 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 774 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Left)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 775 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 776 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 777 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 778 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 779 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 780 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 781 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 782 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 783 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 784 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 785 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 786 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Right)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 787 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 788 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 789 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 790 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 791 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 792 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 793 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 794 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 795 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 796 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 797 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 798 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 799 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 800 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 801 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 802 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 803 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 804 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 805 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 806 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 807 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 808 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 809 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 810 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 811 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Right)\n",
            "GA\u001b[41mS\u001b[0mBG\n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 812 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 813 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GAS\u001b[41mB\u001b[0mG\n",
            "  (Right)\n",
            "GASB\u001b[41mG\u001b[0m\n",
            "Episode: 814 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 815 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 816 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 817 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 818 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 819 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 820 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 821 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 822 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 823 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 824 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 825 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 826 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 827 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 828 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 829 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 830 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 831 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 832 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 833 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 834 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 835 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 836 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 837 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 838 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 839 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 840 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 841 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 842 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Right)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 843 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 844 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Left)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 845 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 846 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 847 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 848 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 849 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 850 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 851 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 852 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 853 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 854 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 855 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 856 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 857 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 858 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 859 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 860 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Left)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 861 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 862 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 863 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 864 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 865 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 866 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 867 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 868 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 869 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 870 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 871 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 872 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 873 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 874 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 875 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 876 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 877 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 878 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 879 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 880 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 881 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 882 Reward: 50 Steps Taken: 6 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 883 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 884 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 885 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 886 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Left)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 887 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 888 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 889 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 890 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 891 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 892 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 893 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 894 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 895 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 896 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 897 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 898 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 899 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 900 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 901 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 902 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 903 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 904 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Right)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 905 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 906 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 907 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 908 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 909 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 910 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 911 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 912 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 913 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 914 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 915 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 916 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 917 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 918 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 919 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 920 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 921 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 922 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 923 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 924 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 925 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 926 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 927 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 928 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 929 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 930 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 931 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 932 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 933 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 934 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 935 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 936 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 937 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 938 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 939 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 940 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Left)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 941 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 942 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 943 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 944 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 945 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 946 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 947 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 948 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 949 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 950 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 951 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 952 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 953 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 954 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 955 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 956 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 957 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 958 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 959 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 960 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 961 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 962 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 963 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 964 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 965 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 966 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 967 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 968 Reward: 30 Steps Taken: 8 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 969 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 970 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 971 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 972 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 973 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 974 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 975 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 976 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 977 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 978 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 979 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 980 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 981 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 982 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 983 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 984 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 985 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 986 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 987 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 988 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 989 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GAS\u001b[41mB\u001b[0mG\n",
            "  (Right)\n",
            "GASB\u001b[41mG\u001b[0m\n",
            "Episode: 990 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 991 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Right)\n",
            "GA\u001b[41mS\u001b[0mBG\n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 992 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 993 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 994 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 995 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 996 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 997 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 998 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 999 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1000 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1001 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1002 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1003 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1004 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1005 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Right)\n",
            "GA\u001b[41mS\u001b[0mBG\n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1006 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1007 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1008 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1009 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1010 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1011 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1012 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1013 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1014 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Right)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1015 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1016 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1017 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1018 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1019 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1020 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1021 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1022 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1023 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1024 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1025 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1026 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1027 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1028 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1029 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1030 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Right)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1031 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1032 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1033 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1034 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1035 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1036 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Left)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1037 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1038 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1039 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1040 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1041 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1042 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1043 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1044 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1045 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1046 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1047 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1048 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1049 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1050 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1051 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1052 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1053 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1054 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1055 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1056 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1057 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1058 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1059 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1060 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1061 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1062 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1063 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1064 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1065 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1066 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1067 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1068 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1069 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1070 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1071 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1072 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1073 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1074 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1075 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1076 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1077 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1078 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1079 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1080 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1081 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1082 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1083 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1084 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Left)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1085 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1086 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1087 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1088 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1089 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1090 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1091 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1092 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1093 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1094 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1095 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1096 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1097 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Right)\n",
            "GA\u001b[41mS\u001b[0mBG\n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1098 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1099 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1100 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1101 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1102 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Left)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1103 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1104 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1105 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1106 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Left)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1107 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1108 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Right)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1109 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1110 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1111 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1112 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1113 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1114 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1115 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1116 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1117 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1118 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1119 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1120 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1121 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1122 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1123 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1124 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1125 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1126 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1127 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1128 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Right)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1129 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1130 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Right)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1131 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1132 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1133 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1134 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Left)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1135 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1136 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1137 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1138 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1139 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1140 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1141 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1142 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1143 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1144 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1145 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1146 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Left)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1147 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1148 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1149 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1150 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1151 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GAS\u001b[41mB\u001b[0mG\n",
            "  (Right)\n",
            "GASB\u001b[41mG\u001b[0m\n",
            "Episode: 1152 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1153 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1154 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1155 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1156 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1157 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1158 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1159 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1160 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1161 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1162 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1163 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1164 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Left)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1165 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1166 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1167 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1168 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1169 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1170 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1171 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1172 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1173 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1174 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Right)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1175 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1176 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1177 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1178 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1179 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1180 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Left)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1181 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1182 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1183 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1184 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1185 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1186 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1187 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1188 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1189 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1190 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1191 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1192 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1193 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1194 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1195 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1196 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1197 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1198 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1199 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1200 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1201 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1202 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1203 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1204 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1205 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1206 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1207 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1208 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1209 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1210 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1211 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1212 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1213 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1214 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1215 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1216 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1217 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1218 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1219 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1220 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1221 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1222 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1223 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1224 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1225 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1226 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1227 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1228 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1229 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1230 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1231 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1232 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1233 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1234 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1235 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1236 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1237 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1238 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1239 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1240 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1241 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1242 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1243 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1244 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1245 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1246 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1247 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1248 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1249 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1250 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1251 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1252 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1253 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1254 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1255 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Right)\n",
            "GA\u001b[41mS\u001b[0mBG\n",
            "  (Right)\n",
            "GAS\u001b[41mB\u001b[0mG\n",
            "  (Right)\n",
            "GASB\u001b[41mG\u001b[0m\n",
            "Episode: 1256 Reward: -40 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1257 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1258 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1259 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Right)\n",
            "GA\u001b[41mS\u001b[0mBG\n",
            "  (Right)\n",
            "GAS\u001b[41mB\u001b[0mG\n",
            "  (Right)\n",
            "GASB\u001b[41mG\u001b[0m\n",
            "Episode: 1260 Reward: -40 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1261 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1262 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1263 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1264 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1265 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1266 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1267 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1268 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1269 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1270 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1271 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1272 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1273 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1274 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Right)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1275 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1276 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1277 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1278 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1279 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1280 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1281 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1282 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Left)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1283 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1284 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1285 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1286 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1287 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1288 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1289 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1290 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1291 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1292 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1293 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1294 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1295 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1296 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1297 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1298 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1299 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1300 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1301 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1302 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1303 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1304 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1305 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1306 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1307 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1308 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1309 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1310 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1311 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1312 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1313 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1314 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1315 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1316 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1317 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1318 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1319 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1320 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1321 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1322 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1323 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1324 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1325 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1326 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1327 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1328 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1329 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1330 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Right)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1331 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1332 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1333 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1334 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1335 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GAS\u001b[41mB\u001b[0mG\n",
            "  (Right)\n",
            "GASB\u001b[41mG\u001b[0m\n",
            "Episode: 1336 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1337 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1338 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1339 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1340 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Left)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1341 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1342 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1343 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1344 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1345 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1346 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1347 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1348 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1349 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1350 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1351 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1352 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Left)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1353 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1354 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1355 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1356 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1357 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1358 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1359 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1360 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1361 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1362 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1363 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1364 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1365 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1366 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1367 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1368 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1369 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1370 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1371 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1372 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1373 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1374 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1375 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1376 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Right)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1377 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1378 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1379 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1380 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1381 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1382 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1383 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1384 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1385 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1386 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Right)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1387 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1388 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Left)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1389 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1390 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1391 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1392 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1393 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1394 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1395 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1396 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1397 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1398 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1399 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1400 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1401 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1402 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1403 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1404 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1405 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1406 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1407 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1408 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1409 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1410 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1411 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1412 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1413 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1414 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1415 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1416 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1417 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1418 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1419 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1420 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1421 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1422 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Right)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1423 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1424 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1425 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1426 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1427 Reward: -20 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1428 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1429 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1430 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1431 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1432 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1433 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1434 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1435 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1436 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Right)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1437 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1438 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1439 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1440 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1441 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1442 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1443 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1444 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1445 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1446 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1447 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1448 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1449 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1450 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1451 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1452 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1453 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1454 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1455 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1456 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1457 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1458 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1459 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1460 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1461 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1462 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1463 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1464 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1465 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1466 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Left)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1467 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1468 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1469 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1470 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1471 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1472 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1473 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1474 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1475 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1476 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Right)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1477 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1478 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Left)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1479 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1480 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Right)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1481 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1482 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1483 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1484 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1485 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1486 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1487 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1488 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1489 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1490 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1491 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "  (Right)\n",
            "GBSA\u001b[41mG\u001b[0m\n",
            "Episode: 1492 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Right)\n",
            "GBS\u001b[41mA\u001b[0mG\n",
            "  (Left)\n",
            "GB\u001b[41mS\u001b[0mAG\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1493 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1494 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1495 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mA\u001b[0mSBG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mASBG\n",
            "Episode: 1496 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: A, Environment: ['GASBG']\n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1497 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1498 Reward: 70 Steps Taken: 4 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n",
            "  (Left)\n",
            "G\u001b[41mB\u001b[0mSAG\n",
            "  (Left)\n",
            "\u001b[41mG\u001b[0mBSAG\n",
            "Episode: 1499 Reward: 90 Steps Taken: 2 , Epsilon: 0.09990224980716131, Entrance_Stimulus: B, Environment:['GBSAG'] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "HeGzODr5MM-M",
        "outputId": "02ae6406-4763-45f8-f67c-e1b964b49753"
      },
      "source": [
        "# env1 and entrance stimulus = 'A'\n",
        "\n",
        "# GASBG\n",
        "\n",
        "Q1.loc[:, [0,2]]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000864</td>\n",
              "      <td>0.000051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>90.000778</td>\n",
              "      <td>43.900261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>71.000700</td>\n",
              "      <td>-47.475576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-41.250552</td>\n",
              "      <td>-21.979529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000524</td>\n",
              "      <td>0.000136</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           0          2\n",
              "0   0.000864   0.000051\n",
              "1  90.000778  43.900261\n",
              "2  71.000700 -47.475576\n",
              "3 -41.250552 -21.979529\n",
              "4   0.000524   0.000136"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "l_uRtFGyM3gL",
        "outputId": "35c345f1-9d5c-46b9-bd53-50668596ff29"
      },
      "source": [
        "# env1 and entrance stimulus = 'B'\n",
        "# TBSAT\n",
        "\n",
        "Q2.loc[:, [0,2]]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000570</td>\n",
              "      <td>0.000064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-21.824687</td>\n",
              "      <td>43.886976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>29.186117</td>\n",
              "      <td>52.808778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>43.494017</td>\n",
              "      <td>71.982344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000403</td>\n",
              "      <td>0.000359</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           0          2\n",
              "0   0.000570   0.000064\n",
              "1 -21.824687  43.886976\n",
              "2  29.186117  52.808778\n",
              "3  43.494017  71.982344\n",
              "4   0.000403   0.000359"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "1Xr_gXzPNID3",
        "outputId": "5c46fdc4-ff48-4ca3-96cd-8fc09eceed88"
      },
      "source": [
        "# env2 and entrance stimulus = 'A'\n",
        "\n",
        "Q3.loc[:, [0,2]]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000949</td>\n",
              "      <td>0.000336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-21.802744</td>\n",
              "      <td>16.044674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>27.277795</td>\n",
              "      <td>67.389086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30.631831</td>\n",
              "      <td>89.800694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000549</td>\n",
              "      <td>0.000542</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           0          2\n",
              "0   0.000949   0.000336\n",
              "1 -21.802744  16.044674\n",
              "2  27.277795  67.389086\n",
              "3  30.631831  89.800694\n",
              "4   0.000549   0.000542"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "gpybKKO_NJ0J",
        "outputId": "f121b323-baf0-498c-d347-40ae2ff54eb6"
      },
      "source": [
        "#env2 and entrance stimulus = 'B'\n",
        "\n",
        "Q4.loc[:, [0,2]]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000426</td>\n",
              "      <td>0.000220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>89.982383</td>\n",
              "      <td>43.900125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>70.544945</td>\n",
              "      <td>27.018484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>43.753142</td>\n",
              "      <td>-20.005484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000108</td>\n",
              "      <td>0.000306</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           0          2\n",
              "0   0.000426   0.000220\n",
              "1  89.982383  43.900125\n",
              "2  70.544945  27.018484\n",
              "3  43.753142 -20.005484\n",
              "4   0.000108   0.000306"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wMLtHeLQidb"
      },
      "source": [
        "When the bee was trained, it was aware of the stimulus at the entrance,\n",
        "and the locations of the two stimuli in the distinct chamber. \n",
        "\n",
        "Hypothesis: Through training it was exposed to four different environments, \n",
        "\n",
        "the algo above shows that if we set up four different Q-tables for each of those environments, a trained agent will be able to choose the correct \n",
        "Q table for performing the right action in each scenario. \n"
      ]
    }
  ]
}